{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter File Drag & Drop Widget - Demo\n",
    "\n",
    "This notebook demonstrates how to use the drag-and-drop file upload widget for JupyterLab.\n",
    "\n",
    "**Supported file formats:**\n",
    "- CSV (`.csv`)\n",
    "- Excel (`.xlsx`, `.xlsm`, `.xls`) - with multi-sheet support\n",
    "- Feather (`.feather`)\n",
    "- Parquet (`.parquet`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FileDrop: Quick Start\n",
    "\n",
    "The `FileDrop` class provides a simple one-line API for drag-and-drop file uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')  # Add parent directory to find the module\n",
    "\n",
    "from ipyfiledrop import FileDrop\n",
    "\n",
    "# One-line creation with named drop zones\n",
    "fd = FileDrop(\"Dataset A\", \"Dataset B\")\n",
    "fd.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access loaded DataFrames\n",
    "print(\"Loaded datasets:\", list(fd.datasets.keys()))\n",
    "\n",
    "# Access individual DataFrame (returns selected sheet for Excel files)\n",
    "df_a = fd[\"Dataset A\"]  # Returns DataFrame or None\n",
    "if df_a is not None:\n",
    "    print(f\"Dataset A shape: {df_a.shape}\")\n",
    "    display(df_a.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-Sheet Excel Support\n",
    "\n",
    "When you drop an Excel file with multiple sheets, a **dropdown selector** appears to switch between sheets.\n",
    "\n",
    "**Try it:** Drop an Excel file with multiple sheets to see the dropdown appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a widget for Excel files\n",
    "fd_excel = FileDrop(\"Excel Data\")\n",
    "fd_excel.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_excel['Excel Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dropping a multi-sheet Excel file:\n",
    "\n",
    "# Get the currently selected DataFrame\n",
    "df = fd_excel[\"Excel Data\"]\n",
    "if df is not None:\n",
    "    print(f\"Selected sheet shape: {df.shape}\")\n",
    "\n",
    "# Get ALL sheets as a dictionary\n",
    "all_sheets = fd_excel.get_all_sheets(\"Excel Data\")\n",
    "if all_sheets:\n",
    "    print(f\"\\nAvailable sheets: {list(all_sheets.keys())}\")\n",
    "    for name, sheet_df in all_sheets.items():\n",
    "        print(f\"  - {name}: {sheet_df.shape[0]} rows × {sheet_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatically select a different sheet\n",
    "# (This also updates the dropdown in the widget)\n",
    "\n",
    "if fd_excel.get_all_sheets(\"Excel Data\"):\n",
    "    sheets = list(fd_excel.get_all_sheets(\"Excel Data\").keys())\n",
    "    if len(sheets) > 1:\n",
    "        fd_excel.select_sheet(\"Excel Data\", sheets[1])  # Select second sheet\n",
    "        print(f\"Selected sheet: {sheets[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. All Supported File Formats\n",
    "\n",
    "The widget supports CSV, Excel (xlsx/xlsm/xls), Feather, and Parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create drop zones for different file types\n",
    "fd_formats = FileDrop(\"CSV\", \"Excel\", \"Feather\", \"Parquet\")\n",
    "fd_formats.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's loaded\n",
    "for label in [\"CSV\", \"Excel\", \"Feather\", \"Parquet\"]:\n",
    "    df = fd_formats[label]\n",
    "    if df is not None:\n",
    "        print(f\"{label}: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "    else:\n",
    "        print(f\"{label}: (no file loaded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dynamic Drop Zone Management\n",
    "\n",
    "Add or remove drop zones dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_dynamic = FileDrop(\"Initial\")\n",
    "fd_dynamic.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new drop zones (method chaining supported)\n",
    "fd_dynamic.add(\"Added 1\").add(\"Added 2\")\n",
    "print(fd_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a drop zone\n",
    "fd_dynamic.remove(\"Added 1\")\n",
    "print(fd_dynamic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedding in ipywidgets Containers\n",
    "\n",
    "Use the `.ui` property to embed FileDrop in Accordion, Tab, VBox, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Embedding in Accordion\n",
    "fd_acc1 = FileDrop(\"Training\", \"Validation\")\n",
    "fd_acc2 = FileDrop(\"Test\", retain_data=True)\n",
    "\n",
    "accordion = widgets.Accordion(children=[fd_acc1.ui, fd_acc2.ui])\n",
    "accordion.set_title(0, \"Train/Val Data\")\n",
    "accordion.set_title(1, \"Test Data\")\n",
    "\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding in Tab\n",
    "fd_tab1 = FileDrop(\"CSV Files\")\n",
    "fd_tab2 = FileDrop(\"Excel Files\")\n",
    "\n",
    "tab = widgets.Tab(children=[fd_tab1.ui, fd_tab2.ui])\n",
    "tab.set_title(0, \"CSV\")\n",
    "tab.set_title(1, \"Excel\")\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding with a button and output\n",
    "fd_btn = FileDrop(\"Upload\")\n",
    "btn = widgets.Button(description=\"Process Data\", button_style=\"primary\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        df = fd_btn[\"Upload\"]\n",
    "        if df is not None:\n",
    "            print(f\"Processing {df.shape[0]} rows...\")\n",
    "            display(df.describe())\n",
    "        else:\n",
    "            print(\"No file uploaded yet!\")\n",
    "\n",
    "btn.on_click(on_click)\n",
    "\n",
    "display(widgets.VBox([fd_btn.ui, btn, output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. IFrameDropWidget: Low-Level API\n",
    "\n",
    "For more control, use `IFrameDropWidget` directly with the `on_data_ready` callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyfiledrop import IFrameDropWidget\n",
    "\n",
    "# Install global listener (FileDrop does this automatically)\n",
    "IFrameDropWidget.install_global_listener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback - receives Dict[str, DataFrame]\n",
    "def on_data_ready(filename, data):\n",
    "    \"\"\"Called when a file is loaded.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the uploaded file\n",
    "        data: Dict[str, DataFrame] - keys are sheet names for Excel, 'data' for others\n",
    "    \"\"\"\n",
    "    print(f\"\\nLoaded: {filename}\")\n",
    "    print(f\"Sheets/Keys: {list(data.keys())}\")\n",
    "    for name, df in data.items():\n",
    "        print(f\"  {name}: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "\n",
    "# Create widget with callback\n",
    "widget = IFrameDropWidget(on_data_ready=on_data_ready)\n",
    "widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data via properties\n",
    "if widget.data:\n",
    "    print(f\"Available sheets: {widget.sheet_names}\")\n",
    "    print(f\"Currently selected: {widget.selected_key}\")\n",
    "    print(f\"\\nSelected DataFrame:\")\n",
    "    display(widget.selected_dataframe.head())\n",
    "else:\n",
    "    print(\"No data loaded yet. Drop a file in the widget above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multi-File Drop & Archive Support\n",
    "\n",
    "Use `retain_data=True` to accumulate multiple files. Archives (.zip, .tar.gz) are automatically extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate mode - files stack up instead of replacing\n",
    "fd_multi = FileDrop(\"Multi-File\", retain_data=True)\n",
    "fd_multi.display()\n",
    "print(\"Drop multiple files - they will accumulate!\\n\")\n",
    "print(\"You can also drop .zip or .tar.gz archives.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View accumulated data\n",
    "all_data = fd_multi.get_all_data(\"Multi-File\")\n",
    "print(f\"Loaded files: {list(all_data.keys())}\")\n",
    "\n",
    "# Check for failed imports (e.g. unsupported files in an archive)\n",
    "failed = fd_multi.get_failed_imports(\"Multi-File\")\n",
    "if failed:\n",
    "    print(f\"\\nFailed imports:\")\n",
    "    for f in failed:\n",
    "        print(f\"  - {f['filename']}: {f['error']}\")\n",
    "\n",
    "# Clear accumulated data programmatically\n",
    "# fd_multi.clear(\"Multi-File\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Import Pipeline\n",
    "\n",
    "The pipeline automatically extracts core data from messy files, cleans it, and can combine multiple files.\n",
    "\n",
    "**Features:**\n",
    "- `extract_core=True`: Extract core data table from messy files with headers/footers\n",
    "- `clean=\"standard\"`: Apply cleaning preset (normalize columns, drop empty rows, etc.)\n",
    "- `fd.combine()`: Combine multiple DataFrames into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the pipeline with sample messy data\n",
    "import pandas as pd\n",
    "from ipyfiledrop import extract_core_data, clean_dataframe, combine_dataframes\n",
    "\n",
    "# Load the messy sample_log.csv directly (simulating what happens on drop)\n",
    "raw = pd.read_csv('data/sparse_messy/sample_log.csv', header=None)\n",
    "print(f\"Raw data shape: {raw.shape}\")\n",
    "print(f\"\\nRaw data preview (first 8 rows):\")\n",
    "display(raw.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract core data from the messy file\n",
    "result = extract_core_data(raw)\n",
    "\n",
    "print(f\"Extraction Results:\")\n",
    "print(f\"  Core shape: {result.core.shape}\")\n",
    "print(f\"  Header row detected: {result.header_row}\")\n",
    "print(f\"  Data range: rows {result.data_range[0]}-{result.data_range[1]}\")\n",
    "print(f\"  Confidence: {result.confidence:.2f}\")\n",
    "print(f\"\\nExtracted metadata: {result.metadata}\")\n",
    "print(f\"Extracted footer: {result.footer}\")\n",
    "print(f\"\\nCore data preview:\")\n",
    "display(result.core.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning to normalize column names and remove empty rows\n",
    "cleaned = clean_dataframe(result.core, preset='standard')\n",
    "\n",
    "print(f\"Cleaned columns: {list(cleaned.columns)}\")\n",
    "print(f\"Cleaned shape: {cleaned.shape}\")\n",
    "display(cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiple DataFrames with source tracking\n",
    "data = {\n",
    "    'batch1.csv': cleaned.head(5),\n",
    "    'batch2.csv': cleaned.tail(5),\n",
    "}\n",
    "combined = combine_dataframes(data, add_source=True)\n",
    "\n",
    "print(f\"Combined shape: {combined.shape}\")\n",
    "print(f\"Sources: {combined['_source'].unique().tolist()}\")\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. FileDrop with Pipeline Integration\n",
    "\n",
    "Use `extract_core` and `clean` parameters directly in FileDrop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FileDrop with pipeline enabled\n",
    "# - extract_core: Automatically extract core data from messy files\n",
    "# - clean: Apply 'standard' cleaning preset\n",
    "# - retain_data: Accumulate multiple files\n",
    "\n",
    "fd_pipeline = FileDrop(\n",
    "    \"Messy Data\",\n",
    "    extract_core=True,\n",
    "    clean=\"standard\",\n",
    "    retain_data=True\n",
    ")\n",
    "fd_pipeline.display()\n",
    "\n",
    "print(\"Drop data/sparse_messy/sample_log.csv to test the pipeline!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dropping a file, access extracted data\n",
    "try:\n",
    "    extracted = fd_pipeline.extract(\"Messy Data\")\n",
    "    print(f\"Core shape: {extracted.core.shape}\")\n",
    "    print(f\"Metadata: {extracted.metadata}\")\n",
    "    print(f\"Footer: {extracted.footer}\")\n",
    "    print(f\"Confidence: {extracted.confidence:.2f}\")\n",
    "except ValueError as e:\n",
    "    print(f\"No data yet: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dropped files into one DataFrame\n",
    "try:\n",
    "    combined = fd_pipeline.combine(\"Messy Data\", add_source=True)\n",
    "    print(f\"Combined shape: {combined.shape}\")\n",
    "    display(combined.head(10))\n",
    "except ValueError as e:\n",
    "    print(f\"No data yet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleaning Presets\n",
    "\n",
    "Available presets: `'none'`, `'minimal'`, `'standard'`, `'aggressive'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyfiledrop import CLEANING_PRESETS\n",
    "\n",
    "for name, cleaners in CLEANING_PRESETS.items():\n",
    "    cleaner_names = [c.__name__ for c in cleaners]\n",
    "    print(f\"{name}: {cleaner_names if cleaner_names else '(no cleaning)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Use individual cleaners for custom pipeline\n",
    "from ipyfiledrop import normalize_columns, strip_whitespace, drop_empty_rows\n",
    "\n",
    "# Custom cleaner chain\n",
    "fd_custom = FileDrop(\n",
    "    \"Custom Clean\",\n",
    "    cleaners=[normalize_columns, strip_whitespace, drop_empty_rows]\n",
    ")\n",
    "fd_custom.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_custom[\"Custom Clean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Column Options\n",
    "\n",
    "The `normalize_columns` cleaner has options to preserve:\n",
    "- `preserve_case=True`: Keep original case (default: lowercase)\n",
    "- `preserve_dashes=True`: Keep dashes `-` (default: replace with `_`)\n",
    "- `preserve_dots=True`: Keep dots `.` (default: replace with `_`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ipyfiledrop import normalize_columns, make_normalize_columns\n",
    "\n",
    "# Sample DataFrame with various special characters\n",
    "df = pd.DataFrame({\n",
    "    'Sample-ID': [1, 2],\n",
    "    'Test.Type': ['A', 'B'],\n",
    "    'Result (Value)': [10.5, 20.3],\n",
    "    'Version v1.2': ['x', 'y']\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different normalization options\n",
    "print(\"Default (lowercase, all special chars -> _):\")\n",
    "display(normalize_columns(df))\n",
    "\n",
    "print(\"\\npreserve_dashes=True (keeps dashes for IDs like SAMP-001):\")\n",
    "display(normalize_columns(df, preserve_dashes=True))\n",
    "\n",
    "print(\"\\npreserve_dots=True (keeps dots for versions like v1.2):\")\n",
    "display(normalize_columns(df, preserve_dots=True))\n",
    "\n",
    "print(\"\\npreserve_case=True, preserve_dashes=True:\")\n",
    "display(normalize_columns(df, preserve_case=True, preserve_dashes=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use make_normalize_columns() factory for FileDrop cleaner chains\n",
    "from ipyfiledrop import make_normalize_columns, strip_whitespace, drop_empty_rows\n",
    "\n",
    "fd_preserve = FileDrop(\n",
    "    \"Preserve Special Chars\",\n",
    "    cleaners=[\n",
    "        make_normalize_columns(preserve_case=True, preserve_dashes=True),\n",
    "        strip_whitespace,\n",
    "        drop_empty_rows\n",
    "    ]\n",
    ")\n",
    "fd_preserve.display()\n",
    "print(\"Columns will preserve case and dashes: Sample-ID, Test_Type, etc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_preserve[\"Preserve Special Chars\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Whitespace Options\n",
    "\n",
    "The `strip_whitespace` cleaner removes leading/trailing whitespace. Use `normalize_inner=True` to also collapse multiple inner spaces to a single space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ipyfiledrop import strip_whitespace, make_strip_whitespace\n",
    "\n",
    "# Sample DataFrame with various whitespace issues\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['  John   Doe  ', '  Jane    Smith  '],\n",
    "    'Address': ['  123   Main   St  ', '  456   Oak   Ave  ']\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default: only strip edges, preserve inner whitespace\n",
    "print(\"strip_whitespace() - edges only:\")\n",
    "display(strip_whitespace(df))\n",
    "\n",
    "print(\"\\nstrip_whitespace(normalize_inner=True) - collapse inner spaces:\")\n",
    "display(strip_whitespace(df, normalize_inner=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use make_strip_whitespace() factory for FileDrop cleaner chains\n",
    "from ipyfiledrop import make_strip_whitespace, normalize_columns, drop_empty_rows\n",
    "\n",
    "fd_normalize_ws = FileDrop(\n",
    "    \"Normalize Whitespace\",\n",
    "    cleaners=[\n",
    "        normalize_columns,\n",
    "        make_strip_whitespace(normalize_inner=True),\n",
    "        drop_empty_rows\n",
    "    ]\n",
    ")\n",
    "fd_normalize_ws.display()\n",
    "print(\"Inner whitespace will be collapsed: '  John   Doe  ' -> 'John Doe'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the result after dropping a file\n",
    "fd_normalize_ws[\"Normalize Whitespace\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Full datasets Property\n",
    "\n",
    "The `datasets` property returns all loaded data with full metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FileDrop and load some files\n",
    "fd_meta = FileDrop(\"Data 1\", \"Data 2\")\n",
    "fd_meta.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the datasets property after loading files\n",
    "for label, info in fd_meta.datasets.items():\n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"  Filename: {info['filename']}\")\n",
    "    print(f\"  Selected: {info['selected']}\")\n",
    "    print(f\"  Available sheets: {list(info['data'].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
